{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric_temporal.dataset import METRLADatasetLoader\n",
    "from torch_geometric_temporal.signal import temporal_signal_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = METRLADatasetLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = loader.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test sets\n",
    "train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time, snapshot in enumerate(train_dataset):\n",
    "    print(f\"Snapshot {time}\")\n",
    "    print(f\"x: {snapshot.x.shape}\")\n",
    "    print(f\"edge_index: {snapshot.edge_index.shape}\")\n",
    "    print(f\"edge_attr: {snapshot.edge_attr.shape}\")\n",
    "    print(f\"y: {snapshot.y.shape}\")\n",
    "    break  # Print only the first snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_graph_with_labels(adjacency_matrix, mylabels, data, count):\n",
    "    rows, cols = np.where(adjacency_matrix>0)\n",
    "    edges = zip(rows.tolist(), cols.tolist())\n",
    "    gr = nx.Graph()\n",
    "    gr.add_edges_from(edges)\n",
    "    nx.draw(gr, node_size=500, with_labels=True, node_color=\"tab:cyan\")\n",
    "    plt.title(f'{data} ({count}) graph learnt from 30 epochs ')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'adj_mat.npy'\n",
    "adj = np.load(path)\n",
    "gr=nx.from_numpy_array(adj)\n",
    "print(\"Traffic graph learnt has {} nodes and {} edges\".format(gr.number_of_nodes(),gr.number_of_edges()))\n",
    "show_graph_with_labels(adj[0:100,0:100], range(1,101), \"Traffic Roads\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch_geometric_temporal.dataset import METRLADatasetLoader\n",
    "from torch_geometric_temporal.signal import temporal_signal_split\n",
    "\n",
    "# Check for device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Define the necessary sub-components\n",
    "\n",
    "class nconv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(nconv, self).__init__()\n",
    "\n",
    "    def forward(self, x, A):\n",
    "        x = torch.einsum('ncwl,vw->ncvl', (x, A))\n",
    "        return x.contiguous()\n",
    "\n",
    "class linear(nn.Module):\n",
    "    def __init__(self, c_in, c_out, bias=True):\n",
    "        super(linear, self).__init__()\n",
    "        self.mlp = nn.Conv2d(c_in, c_out, kernel_size=(1, 1), padding=(0, 0), stride=(1, 1), bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "class mixprop(nn.Module):\n",
    "    def __init__(self, c_in, c_out, gdep, dropout, alpha):\n",
    "        super(mixprop, self).__init__()\n",
    "        self.nconv = nconv()\n",
    "        self.mlp = linear((gdep + 1) * c_in, c_out)\n",
    "        self.gdep = gdep\n",
    "        self.dropout = dropout\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        adj = adj + torch.eye(adj.size(0)).to(x.device)\n",
    "        d = adj.sum(1)\n",
    "        h = x\n",
    "        out = [h]\n",
    "        a = adj / d.view(-1, 1)\n",
    "        for i in range(self.gdep):\n",
    "            h = self.alpha * x + (1 - self.alpha) * self.nconv(h, a)\n",
    "            out.append(h)\n",
    "        ho = torch.cat(out, dim=1)\n",
    "        ho = self.mlp(ho)\n",
    "        return ho\n",
    "\n",
    "class dilated_inception(nn.Module):\n",
    "    def __init__(self, cin, cout, dilation_factor=2, kernel_set=[2, 3, 6, 7]):\n",
    "        super(dilated_inception, self).__init__()\n",
    "        self.tconv = nn.ModuleList()\n",
    "        self.kernel_set = kernel_set\n",
    "        cout = int(cout / len(self.kernel_set))\n",
    "        for kern in self.kernel_set:\n",
    "            self.tconv.append(nn.Conv2d(cin, cout, (1, kern), dilation=(1, dilation_factor)))\n",
    "\n",
    "    def forward(self, input):\n",
    "        time_steps = input.size(3)  # Get the time dimension size\n",
    "        x = []\n",
    "        for i in range(len(self.kernel_set)):\n",
    "            kernel_size = self.kernel_set[i]\n",
    "            # Check if kernel size is less than or equal to input sequence length\n",
    "            if kernel_size <= time_steps:\n",
    "                x.append(self.tconv[i](input))\n",
    "            else:\n",
    "                # Skip kernels larger than the sequence length to avoid runtime errors\n",
    "                print(f\"Skipping kernel size {kernel_size} for sequence length {time_steps}\")\n",
    "        # Ensure each output has the same length in the time dimension\n",
    "        for i in range(len(x)):\n",
    "            x[i] = x[i][..., -x[-1].size(3):]\n",
    "        x = torch.cat(x, dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class graph_constructor(nn.Module):\n",
    "    def __init__(self, nnodes, k, dim, device, alpha=3, static_feat=None):\n",
    "        super(graph_constructor, self).__init__()\n",
    "        self.nnodes = nnodes\n",
    "        self.emb1 = nn.Embedding(nnodes, dim)\n",
    "        self.emb2 = nn.Embedding(nnodes, dim)\n",
    "        self.lin1 = nn.Linear(dim, dim)\n",
    "        self.lin2 = nn.Linear(dim, dim)\n",
    "        self.device = device\n",
    "        self.k = k\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, idx):\n",
    "        nodevec1 = self.emb1(idx)\n",
    "        nodevec2 = self.emb2(idx)\n",
    "        nodevec1 = torch.tanh(self.alpha * self.lin1(nodevec1))\n",
    "        nodevec2 = torch.tanh(self.alpha * self.lin2(nodevec2))\n",
    "        a = torch.mm(nodevec1, nodevec2.transpose(1, 0)) - torch.mm(nodevec2, nodevec1.transpose(1, 0))\n",
    "        adj = F.relu(torch.tanh(self.alpha * a))\n",
    "        mask = torch.zeros(idx.size(0), idx.size(0)).to(self.device)\n",
    "        mask.fill_(float('0'))\n",
    "        s1, t1 = (adj + torch.rand_like(adj) * 0.01).topk(self.k, 1)\n",
    "        mask.scatter_(1, t1, s1.fill_(1))\n",
    "        adj = adj * mask\n",
    "        return adj\n",
    "\n",
    "# Define the CustomMTGNN model\n",
    "class CustomMTGNN(nn.Module):\n",
    "    def __init__(self, num_nodes, input_dim, output_dim, gdep, dropout, alpha, dilation_factor):\n",
    "        super(CustomMTGNN, self).__init__()\n",
    "        self.graph_constructor = graph_constructor(nnodes=num_nodes, k=20, dim=40, device=device)\n",
    "        self.mixprop = mixprop(c_in=input_dim, c_out=output_dim, gdep=gdep, dropout=dropout, alpha=alpha)\n",
    "        self.dilated_inception = dilated_inception(cin=output_dim, cout=output_dim, dilation_factor=dilation_factor)\n",
    "        self.output_layer = nn.Conv2d(output_dim, 1, kernel_size=(1, 1), padding=(0, 0), stride=(1, 1))\n",
    "\n",
    "    def forward(self, x, idx):\n",
    "        adj = self.graph_constructor(idx)\n",
    "        x = self.mixprop(x, adj)\n",
    "        x = self.dilated_inception(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Load the METR-LA dataset\n",
    "loader = METRLADatasetLoader()\n",
    "dataset = loader.get_dataset()\n",
    "train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)\n",
    "\n",
    "# Initialize model, optimizer, and loss function\n",
    "num_nodes = dataset[0].x.shape[0]\n",
    "input_dim = dataset[0].x.shape[2]\n",
    "output_dim = 32\n",
    "gdep = 2\n",
    "dropout = 0.3\n",
    "alpha = 0.05\n",
    "dilation_factor = 2\n",
    "\n",
    "model = CustomMTGNN(num_nodes=num_nodes, input_dim=input_dim, output_dim=output_dim, gdep=gdep, dropout=dropout,\n",
    "                    alpha=alpha, dilation_factor=dilation_factor).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10  # Set to a smaller number for testing\n",
    "# Training loop with input reshaping\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for snapshot in train_dataset:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Reshape input x to match model expectations\n",
    "        x = snapshot.x.permute(2, 0, 1).unsqueeze(0).to(device)  # Shape: [1, features, nodes, time_steps]\n",
    "        idx = torch.arange(num_nodes).to(device)\n",
    "        y = snapshot.y.unsqueeze(0).to(device)  # Add batch dimension\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(x, idx)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    print(f'Epoch {epoch + 1}, Train Loss: {total_loss / len(train_dataset):.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
